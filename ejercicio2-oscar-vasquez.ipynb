{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2\n",
    "\n",
    "Este ejercicio pretende poner en práctica la habilidad de limpiar datos y visualizar plots para crear finalmente modelos en __sklearn__.\n",
    "\n",
    "El estudiante tendrá que repasar los comandos realizados en clase y lidiar con posibles errores durante el desarrollo. \n",
    "\n",
    "Para facilitar y agilizar el desarrollo, el estudiante tendrá que rellenar los huecos marcados como __# codigo-alumno__. No obstante, si además el estudiante necesita ejecutar código adicional, siempre podrá utilizar cualquier celda intermedia. \n",
    "\n",
    "Las celdas con el título __\"\"\" No alterar \"\"\"__, no deben ser modificadas por el estudiante. Sin embargo sí que se pueden ejecutar, pues representan controles intermedios para asegurar que no se cometen errores importantes que desvirtuen el desarrollo esperado del ejercicio.\n",
    "\n",
    "Finalmente, la entrega será un fichero .ipynb cambiando nombre y apellido al fichero. No hace falta entregarlo en html/pdf ni comprimirlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase inicial: Preparativos del ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estableceremos una semilla que nos permita generar números aleatorios bajo control.\n",
    "\n",
    "__Importante__: Todos los comandos (incluido algoritmos) generen números aleatorios deberás ser inicializados con esta semilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, cargaremos todos los comandos vistos en el curso. Si el estudiante considera utilizar alguna librería adicional, puede hacerlo en esta fase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "sns.set_style('darkgrid')\n",
    "np.set_printoptions(precision=3)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split, KFold, ShuffleSplit, LeaveOneOut, StratifiedKFold, cross_val_score, cross_val_predict, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, Binarizer, RobustScaler, OneHotEncoder, LabelEncoder, PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajaremos con el dataframe de sklearn llamado _fetch_kddcup99_ y lo almacenacenaremos en una variable. Además, no trabajaremos con todas las variables, sino con las features seleccionadas en _key_colums_ y la variable a predecir _target_.\n",
    "\n",
    "_Nota_: Si tuvieramos problemas en esta celda, lo más probable es que se deba a que tengamos una versión inferior a 0.24 de sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>count</th>\n",
       "      <th>srv_count</th>\n",
       "      <th>serror_rate</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'normal.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'normal.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'normal.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'normal.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'normal.'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  duration protocol_type  service   flag logged_in count srv_count  \\\n",
       "0        0        b'tcp'  b'http'  b'SF'         1     8         8   \n",
       "1        0        b'tcp'  b'http'  b'SF'         1     8         8   \n",
       "2        0        b'tcp'  b'http'  b'SF'         1     8         8   \n",
       "3        0        b'tcp'  b'http'  b'SF'         1     6         6   \n",
       "4        0        b'tcp'  b'http'  b'SF'         1     6         6   \n",
       "\n",
       "  serror_rate dst_host_srv_count dst_host_srv_serror_rate      labels  \n",
       "0         0.0                  9                      0.0  b'normal.'  \n",
       "1         0.0                 19                      0.0  b'normal.'  \n",
       "2         0.0                 29                      0.0  b'normal.'  \n",
       "3         0.0                 39                      0.0  b'normal.'  \n",
       "4         0.0                 49                      0.0  b'normal.'  "
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_kddcup99\n",
    "\n",
    "data = fetch_kddcup99(as_frame=True)\n",
    "df = data.frame\n",
    "\n",
    "key_columns = ['duration', 'protocol_type', 'service', 'flag', 'logged_in', 'count', 'srv_count', 'serror_rate', 'dst_host_srv_count', 'dst_host_srv_serror_rate']\n",
    "target = 'labels'\n",
    "\n",
    "df = df[key_columns + [target]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase exploración, limpieza y transformación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente celda, comprobad que no haya nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente celda, eliminad los registros duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" No alterar \"\"\"\n",
    "\n",
    "try:\n",
    "    assert df.shape == (54165, 11)\n",
    "except:\n",
    "    print('Algo falla')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente celda, mostrad un barplot para la variable objetivo (labels)\n",
    "\n",
    "_Nota_: Un barplot para variables categóricas, no histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, solo trabajaremos con las labels de mayor frecuencia. Por tanto, en la siguiente celda, filtrad el dataframe para quedarnos con las más frecuentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" No alterar \"\"\"\n",
    "\n",
    "try:\n",
    "    assert df.shape == (50177, 11)\n",
    "except:\n",
    "    print('Algo falla')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente celda, volved a mostra un barplot para la variable objetivo (labels) del dataframe ya filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente celda, exploraremos transformaciones sobre las variables numéricas. Para ello, se pide mostrar 3 histogramas por cada feature numérica:\n",
    "* Uno con el valor de la variable \n",
    "* Uno con el valor de la variable transformada por Box-Cox (si es viable)\n",
    "* Uno con el valor de la variable transformada por Yeo-Johnson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por la forma de los histogramas, podría ser un buen estudio convertir las variables numéricas a variables dummy, y es lo que hareis en este apartado. En concreto, en la siguiente celda, realizad una binarización de estas features tomando el criterio que considereis más apropiado.\n",
    "\n",
    "_Nota_: No siempre la media o la mediana es la mejor de los umbrales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" No alterar \"\"\"\n",
    "\n",
    "try:\n",
    "    assert df.shape == (50177, 11)\n",
    "    assert 0 < df['duration'].sum() < 50177\n",
    "    assert 0 < df['count'].sum() < 50177\n",
    "    assert 0 < df['srv_count'].sum() < 50177\n",
    "    assert 0 < df['serror_rate'].sum() < 50177\n",
    "    assert 0 < df['dst_host_srv_count'].sum() < 50177\n",
    "    assert 0 < df['dst_host_srv_serror_rate'].sum() < 50177\n",
    "    assert 0 < df['logged_in'].sum() < 50177\n",
    "except:\n",
    "    print('Algo falla')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar con estas features, en la siguiente celda, se pide mostrar un baplot (no histograma) por cada una de estas variables binarias estratificado por la variable objetivo (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente celda, exploraremos las variables categóricas. Para ello, se pide mostrar un barplot por cada feature categórica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para lo que resta de ejercicio, localizaremos las 2 categorías más frecuentes de las features _flag_ y _service_. En la siguiente celda, se pide transformar estas features para que ponga _resto_ a todos aquellos registros de estas features que no están entre las frecuentes, dejando así 3 catgorías en total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" No alterar \"\"\"\n",
    "\n",
    "try:\n",
    "    assert df.shape == (50177, 11)\n",
    "    assert len(df[df['service'] == 'resto']) == 20395\n",
    "    assert len(df[df['flag'] == 'resto']) == 5778\n",
    "except:\n",
    "    print('Algo falla')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar con estas features, en la siguiente celda, se pide mostrar un baplot (no histograma) por cada una de estas features categóricas estratificado por la variable objetivo (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de empezar con la modelización, eliminad los duplicados en la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" No alterar \"\"\"\n",
    "\n",
    "try:\n",
    "    assert 100 < df.shape[0] < 1000\n",
    "    assert df.shape[1] == 11\n",
    "except:\n",
    "    print('Algo falla')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizad un ajuste de machine learning con las siguientes características:\n",
    "* probad 5 algoritmos en bucle y mostrar un boxplot con los resultados\n",
    "* usad la técnica de validación cruzada KFolds (5 folds) \n",
    "* entrenad solo con variables numericas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizad un ajuste de machine learning con las siguientes características:\n",
    "* probad 5 algoritmos en bucle\n",
    "* usad la técnica de validación KFolds (5 folds) \n",
    "* usad un pipeline que encadene \n",
    "    * One-hot-encoder con las variables tipo string\n",
    "    * algortimo \n",
    "* entrenad con todas las variables\n",
    "* mostrad la matriz de confusión en cada caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizad un ajuste de machine learning en bucle con las siguientes características:\n",
    "* probad 3 PCA dentro del pipeline y en bucle para n_components=3,4,5 \n",
    "* probad 5 algoritmos en bucle\n",
    "* usad la técnica de validación StratifiedKFolds (5 folds) \n",
    "* usad un pipeline que encadene \n",
    "     * One-hot-encoder con las variables tipo string, especificando eliminar la primera columna si es binaria\n",
    "     * PCA\n",
    "     * algortimo \n",
    "* mostrad la matriz de confusión en cada caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el estudio previo que hemos realizado de validación cruzada, ya sabremos qué algoritmos son más robustos. En esta parte, vamos a separar primero el dataset en _train_ y _test_. En concreto, separaremos el 20% del dataset en el _test-set_ con el que validaremos la calidad real del algortimo. Tras ello, solo con el _train test_, se pide realizar un ajuste de machine learning con las siguientes características:\n",
    "* usad el mejor algoritmo a vuestro juicio (pero se pide justificarlo en un comentario del código)\n",
    "* usad un pipeline que encadene \n",
    "    * One-hot-encoder con las variables tipo string, especificando eliminar la primera columna si es binaria\n",
    "    * algortimo \n",
    "* Realizad la predicción de _train_ y _test_ para poder mostrar ambas matrices de confusión (justificar si existe overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el estudio previo que hemos realizado de validación cruzada, ya sabremos qué algoritmos son más robustos. En esta parte, vamos a separar primero el dataset en train y test. En concreto, separaremos el 20% del dataset en el test-set con el que validaremos la calidad real del algortimo. Tras ello, solo con el train test, se pide realizar un ajuste de machine learning con las siguientes características:\n",
    "* usad el mismo algoritmo que en el apartado anterior\n",
    "* usad la técnica de validación cruzada KFolds (5 folds) \n",
    "* usad un pipeline que encadene:\n",
    "     * One-hot-encoder si son tipo variables tipo string, especificando eliminar la primera columna si es binaria\n",
    "     * StandardScaler\n",
    "     * algortimo \n",
    "* realizar un tuneado del modelo con grid-search\n",
    "    \n",
    "Con el mejor de los modelos tuneados, realizad la predicción de _train_ y _test_ para poder mostrar ambas matrices de confusión (justificar si existe overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codigo-alumno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
